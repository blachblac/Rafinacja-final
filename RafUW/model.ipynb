{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1129)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1129)>\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/sklimkowski/Desktop/Rafinacja/model.ipynb Komórka 1\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sklimkowski/Desktop/Rafinacja/model.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sklimkowski/Desktop/Rafinacja/model.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m Counter\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sklimkowski/Desktop/Rafinacja/model.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Embedding\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sklimkowski/Desktop/Rafinacja/model.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m pad_sequences\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sklimkowski/Desktop/Rafinacja/model.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m \u001b[39mimport\u001b[39;00m Tokenizer\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/models/__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/functional.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m layout_map \u001b[39mas\u001b[39;00m layout_map_lib\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from keras.layers import Embedding\n",
    "from keras.utils import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Embedding\n",
    "\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przygotowanie plików"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_review</th>\n",
       "      <th>user_suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm scared and hearing creepy voices.  So I'll...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best game, more better than Sam Pepper's YouTu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A littly iffy on the controls, but once you kn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great game, fun and colorful and all that.A si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not many games have the cute tag right next to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17489</th>\n",
       "      <td>Arguably the single greatest mmorp that exists...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17490</th>\n",
       "      <td>An older game, to be sure, but has its own cha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17491</th>\n",
       "      <td>When I frist started playing Everquest 2 it wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17492</th>\n",
       "      <td>cool game. THe only thing that REALLY PISSES M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17493</th>\n",
       "      <td>this game since I was a little kid, always hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             user_review  user_suggestion\n",
       "0      I'm scared and hearing creepy voices.  So I'll...                1\n",
       "1      Best game, more better than Sam Pepper's YouTu...                1\n",
       "2      A littly iffy on the controls, but once you kn...                1\n",
       "3      Great game, fun and colorful and all that.A si...                1\n",
       "4      Not many games have the cute tag right next to...                1\n",
       "...                                                  ...              ...\n",
       "17489  Arguably the single greatest mmorp that exists...                1\n",
       "17490  An older game, to be sure, but has its own cha...                1\n",
       "17491  When I frist started playing Everquest 2 it wa...                1\n",
       "17492  cool game. THe only thing that REALLY PISSES M...                1\n",
       "17493  this game since I was a little kid, always hav...                1\n",
       "\n",
       "[17494 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Reviews.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Reviews.xlsx')\n",
    "\n",
    "# tworzenie folderów na recenzje\n",
    "if not os.path.exists('positive'):\n",
    "    os.makedirs('positive')\n",
    "if not os.path.exists('negative'):\n",
    "    os.makedirs('negative')\n",
    "\n",
    "pos_file_num = 1\n",
    "neg_file_num = 1\n",
    "\n",
    "# pętla po rzędach\n",
    "for index, row in df.iterrows():\n",
    "    review = row['user_review']\n",
    "    sentiment = row['user_suggestion']\n",
    "    \n",
    "    # zapis jednej recenzji do osobnego pliku .txt i wrzucenie jej do odpowiedniego folderu\n",
    "    if sentiment == 1:\n",
    "        filename = f\"positive/positive-{pos_file_num}.txt\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(review)\n",
    "        pos_file_num += 1\n",
    "    else:\n",
    "        filename = f\"negative/negative-{neg_file_num}.txt\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(review)\n",
    "        neg_file_num += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pliki podzielone na test i trening ręcznie = test_positive ~1090 plików, test_negative ~750"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przetwarzanie tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82896\n",
      "[('game', 44091), ('like', 10393), ('get', 10175), ('play', 9928), ('The', 8236), ('time', 6402), ('good', 6153), ('fun', 5894), ('one', 5744), ('dont', 5736), ('Access', 5314), ('even', 5233), ('really', 5211), ('Early', 5153), ('games', 4825), ('would', 4328), ('playing', 4324), ('new', 4198), ('much', 4121), ('people', 4045), ('free', 4017), ('This', 4003), ('money', 3881), ('players', 3814), ('want', 3671), ('make', 3534), ('still', 3497), ('played', 3299), ('You', 3239), ('great', 3232), ('It', 3201), ('hours', 3163), ('better', 2969), ('pay', 2947), ('Its', 2904), ('also', 2840), ('lot', 2838), ('way', 2723), ('If', 2695), ('many', 2679), ('cant', 2564), ('buy', 2526), ('need', 2514), ('every', 2510), ('first', 2491), ('well', 2484), ('see', 2404), ('go', 2389), ('say', 2364), ('system', 2325)]\n"
     ]
    }
   ],
   "source": [
    "def load_doc(filename):\n",
    "    file = open(filename, 'r', encoding='utf-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "#czyszczenie dokumentu\n",
    "def clean_doc(doc):\n",
    " #podziel przez spacje\n",
    "    tokens = doc.split()\n",
    " #usuń interpunkcję\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    " #usuń niealfabetyczne tokeny\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    " #usuń stop wordy\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    " #usuń tokeny mniejsze niż 2 znaki\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens\n",
    "\n",
    "def add_doc_to_vocab(filename, vocab):\n",
    "    doc = load_doc(filename)\n",
    "    tokens = clean_doc(doc)\n",
    "    vocab.update(tokens)\n",
    "\n",
    "#przejście przez foldery\n",
    "def process_docs(directory, vocab):\n",
    "    for filename in listdir(directory):\n",
    "        path = directory + '/' + filename\n",
    "        add_doc_to_vocab(path, vocab)\n",
    "\n",
    "vocab = Counter()\n",
    "#ścieżki folderów\n",
    "process_docs(r'C:\\Users\\sjkli\\Desktop\\Rafinacja\\positive', vocab)\n",
    "process_docs(r'C:\\Users\\sjkli\\Desktop\\Rafinacja\\negative', vocab)\n",
    "# wielkość korpusu\n",
    "print(len(vocab))\n",
    "# najczęstrze słowa w korpusie\n",
    "print(vocab.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19131\n"
     ]
    }
   ],
   "source": [
    "#usń z korpusu tokeny które występują mniej niż 3 razy\n",
    "min_occurane = 3\n",
    "tokens = [k for k,c in vocab.items() if c >= min_occurane]\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'level',\n",
       " 'Feats',\n",
       " 'bes',\n",
       " 'Decent',\n",
       " 'enjoyement',\n",
       " 'hattori',\n",
       " 'stale',\n",
       " 'armorweapons',\n",
       " 'early',\n",
       " 'Having',\n",
       " 'separates',\n",
       " 'mainline',\n",
       " 'communications',\n",
       " 'glance',\n",
       " 'psychology',\n",
       " 'Fortnight',\n",
       " 'Fires',\n",
       " 'chilling',\n",
       " 'subscribed',\n",
       " 'gaem',\n",
       " 'gimics',\n",
       " 'rewardsHonor',\n",
       " 'Demons',\n",
       " 'examples',\n",
       " 'ginormous',\n",
       " 'AGAIN',\n",
       " 'OYUN',\n",
       " 'magic',\n",
       " 'manually',\n",
       " 'Indar',\n",
       " 'Theyve',\n",
       " 'macro',\n",
       " 'Modes',\n",
       " 'unbalanced',\n",
       " 'moreIf',\n",
       " 'hive',\n",
       " 'experimented',\n",
       " 'flaming',\n",
       " 'stat',\n",
       " 'sequences',\n",
       " 'Yellow',\n",
       " 'ESL',\n",
       " 'Slot',\n",
       " 'boy',\n",
       " 'picks',\n",
       " 'stars',\n",
       " 'providing',\n",
       " 'committed',\n",
       " 'dumpster',\n",
       " 'largely',\n",
       " 'Download',\n",
       " 'maintained',\n",
       " 'presumably',\n",
       " 'Forgive',\n",
       " 'Cryptics',\n",
       " 'CONNECTION',\n",
       " 'stil',\n",
       " 'Aviation',\n",
       " 'pad',\n",
       " 'defensive',\n",
       " 'fun',\n",
       " 'hey',\n",
       " 'Microtransactions',\n",
       " 'gravity',\n",
       " 'infused',\n",
       " 'blizzard',\n",
       " 'wil',\n",
       " 'HoTS',\n",
       " 'Stream',\n",
       " 'vendor',\n",
       " 'editing',\n",
       " 'Admittedly',\n",
       " 'heard',\n",
       " 'Unfortunately',\n",
       " 'printed',\n",
       " 'misunderstanding',\n",
       " 'pins',\n",
       " 'Exile',\n",
       " 'judgement',\n",
       " 'dash',\n",
       " 'transfering',\n",
       " 'cautious',\n",
       " 'improperly',\n",
       " 'shtty',\n",
       " 'panther',\n",
       " 'grindier',\n",
       " 'score',\n",
       " 'Isnt',\n",
       " 'crawls',\n",
       " 'Other',\n",
       " 'respects',\n",
       " 'TV',\n",
       " 'sons',\n",
       " 'deca',\n",
       " 'referred',\n",
       " 'easeThe',\n",
       " 'moreBut',\n",
       " 'hella',\n",
       " 'timeIt',\n",
       " 'place',\n",
       " 'FreeToPlay',\n",
       " 'pressured',\n",
       " 'fills',\n",
       " 'aesthetic',\n",
       " 'ABOVE',\n",
       " 'disaster',\n",
       " 'HATE',\n",
       " 'sadness',\n",
       " 'STARTED',\n",
       " 'Friends',\n",
       " 'upward',\n",
       " 'KAYIP',\n",
       " 'gameIve',\n",
       " 'Domination',\n",
       " 'tad',\n",
       " 'everywhereThe',\n",
       " 'suggestions',\n",
       " 'Randomly',\n",
       " 'Thumbs',\n",
       " 'deny',\n",
       " 'avoided',\n",
       " 'cardI',\n",
       " 'JK',\n",
       " 'positive',\n",
       " 'LETS',\n",
       " 'Erez',\n",
       " 'rng',\n",
       " 'mega',\n",
       " 'RotMG',\n",
       " 'sunlight',\n",
       " 'Main',\n",
       " 'Baby',\n",
       " 'soley',\n",
       " 'Control',\n",
       " 'ull',\n",
       " 'skewed',\n",
       " 'versions',\n",
       " 'gameplayThe',\n",
       " 'Stars',\n",
       " 'testament',\n",
       " 'tank',\n",
       " 'statistics',\n",
       " 'admin',\n",
       " 'Crates',\n",
       " 'Puch',\n",
       " 'MPX',\n",
       " 'CLICK',\n",
       " 'sandbox',\n",
       " 'las',\n",
       " 'fanatic',\n",
       " 'tones',\n",
       " 'thisThe',\n",
       " 'renamed',\n",
       " 'pigs',\n",
       " 'fractured',\n",
       " 'flight',\n",
       " 'wishing',\n",
       " 'cratesand',\n",
       " 'onetime',\n",
       " 'thoughtful',\n",
       " 'moderately',\n",
       " 'SOME',\n",
       " 'ideally',\n",
       " 'Old',\n",
       " 'Rotmg',\n",
       " 'rando',\n",
       " 'traverse',\n",
       " 'definitive',\n",
       " 'bindings',\n",
       " 'Came',\n",
       " 'accuracy',\n",
       " 'track',\n",
       " 'Shermans',\n",
       " 'ReviewExcellent',\n",
       " 'Store',\n",
       " 'Zeus',\n",
       " 'allow',\n",
       " 'verifying',\n",
       " 'drowned',\n",
       " 'processes',\n",
       " 'brokenNo',\n",
       " 'rampage',\n",
       " 'ID',\n",
       " 'CRACK',\n",
       " 'ame',\n",
       " 'plasmas',\n",
       " 'flowing',\n",
       " 'Ive',\n",
       " 'POS',\n",
       " 'doo',\n",
       " 'essential',\n",
       " 'river',\n",
       " 'fk',\n",
       " 'Snipers',\n",
       " 'downfalls',\n",
       " 'tottaly',\n",
       " 'leaf',\n",
       " 'beatem',\n",
       " 'pace',\n",
       " 'Currently',\n",
       " 'inevitable',\n",
       " 'updater',\n",
       " 'father',\n",
       " 'HiRez',\n",
       " 'awake',\n",
       " 'comp',\n",
       " 'splitting',\n",
       " 'sharks',\n",
       " 'PEOPLE',\n",
       " 'remembered',\n",
       " 'SIDE',\n",
       " 'Finished',\n",
       " 'plastic',\n",
       " 'DRAW',\n",
       " 'tooYou',\n",
       " 'Nest',\n",
       " 'smack',\n",
       " 'rooted',\n",
       " 'slashing',\n",
       " 'ffs',\n",
       " 'min',\n",
       " 'decks',\n",
       " 'poor',\n",
       " 'unwinnable',\n",
       " 'butter',\n",
       " 'bikes',\n",
       " 'ar',\n",
       " 'DX',\n",
       " 'suits',\n",
       " 'Idk',\n",
       " 'meters',\n",
       " 'Doto',\n",
       " 'speech',\n",
       " 'DROP',\n",
       " 'aids',\n",
       " 'convince',\n",
       " 'decisions',\n",
       " 'happy',\n",
       " 'troll',\n",
       " 'wht',\n",
       " 'collision',\n",
       " 'reinstall',\n",
       " 'avaible',\n",
       " 'generates',\n",
       " 'DIFFERENT',\n",
       " 'fetch',\n",
       " 'wooden',\n",
       " 'capture',\n",
       " 'Dodging',\n",
       " 'scathing',\n",
       " 'fluff',\n",
       " 'curently',\n",
       " 'antivirus',\n",
       " 'russians',\n",
       " 'secondary',\n",
       " 'humiliated',\n",
       " 'Resource',\n",
       " 'officially',\n",
       " 'Intuitive',\n",
       " 'incorrectly',\n",
       " 'Simulators',\n",
       " 'relative',\n",
       " 'technological',\n",
       " 'PROBLEM',\n",
       " 'COUGH',\n",
       " 'fiddle',\n",
       " 'cesspool',\n",
       " 'offs',\n",
       " 'PC',\n",
       " 'lifts',\n",
       " 'begining',\n",
       " 'Monoply',\n",
       " 'given',\n",
       " 'everone',\n",
       " 'MAPS',\n",
       " 'burgeoning',\n",
       " 'flabbergasted',\n",
       " 'gametime',\n",
       " 'thanks',\n",
       " 'aslong',\n",
       " 'blowing',\n",
       " 'crawlers',\n",
       " 'EASY',\n",
       " 'emerge',\n",
       " 'consistantly',\n",
       " 'okay',\n",
       " 'ze',\n",
       " 'worstThe',\n",
       " 'illusion',\n",
       " 'says',\n",
       " 'dispenser',\n",
       " 'PLAY',\n",
       " 'titles',\n",
       " 'ReviewUpdate',\n",
       " 'itemsI',\n",
       " 'anytime',\n",
       " 'Publisher',\n",
       " 'grip',\n",
       " 'mulligans',\n",
       " 'MyM',\n",
       " 'Extra',\n",
       " 'playtested',\n",
       " 'Kept',\n",
       " 'anyway',\n",
       " 'ReviewId',\n",
       " 'backstab',\n",
       " 'Plane',\n",
       " 'camp',\n",
       " 'PvP',\n",
       " 'short',\n",
       " 'missions',\n",
       " 'appearently',\n",
       " 'modifying',\n",
       " 'trusted',\n",
       " 'solves',\n",
       " 'queues',\n",
       " 'baseball',\n",
       " 'UNINSTALL',\n",
       " 'varying',\n",
       " 'Arms',\n",
       " 'rereview',\n",
       " 'Incredibly',\n",
       " 'newcomer',\n",
       " 'drones',\n",
       " 'stabbing',\n",
       " 'strats',\n",
       " 'ja',\n",
       " 'impressive',\n",
       " 'wa',\n",
       " 'unbind',\n",
       " 'DECK',\n",
       " 'mockery',\n",
       " 'Repair',\n",
       " 'Angel',\n",
       " 'blocked',\n",
       " 'succeeded',\n",
       " 'unhelpful',\n",
       " 'hoverblades',\n",
       " 'away',\n",
       " 'song',\n",
       " 'visibly',\n",
       " 'voiceover',\n",
       " 'spoiling',\n",
       " 'suspect',\n",
       " 'gameAs',\n",
       " 'ocean',\n",
       " 'MM',\n",
       " 'homes',\n",
       " 'Ryzen',\n",
       " 'outfit',\n",
       " 'inherently',\n",
       " 'subtitle',\n",
       " 'exept',\n",
       " 'fantasticThe',\n",
       " 'anybody',\n",
       " 'dual',\n",
       " 'wan',\n",
       " 'exposed',\n",
       " 'modelling',\n",
       " 'Daily',\n",
       " 'funding',\n",
       " 'sprint',\n",
       " 'yrs',\n",
       " 'spamming',\n",
       " 'agile',\n",
       " 'bogged',\n",
       " 'Endurance',\n",
       " 'wellrounded',\n",
       " 'alley',\n",
       " 'anf',\n",
       " 'YesAre',\n",
       " 'earlygame',\n",
       " 'whatnot',\n",
       " 'gauge',\n",
       " 'toned',\n",
       " 'Kudos',\n",
       " 'ReviewAll',\n",
       " 'approaching',\n",
       " 'adjusted',\n",
       " 'takeoff',\n",
       " 'skirmish',\n",
       " 'Royale',\n",
       " 'controlers',\n",
       " 'territory',\n",
       " 'AS',\n",
       " 'almost',\n",
       " 'Mirana',\n",
       " 'appeared',\n",
       " 'homosexual',\n",
       " 'Eastern',\n",
       " 'HIRez',\n",
       " 'tri',\n",
       " 'percieved',\n",
       " 'jest',\n",
       " 'tempered',\n",
       " 'punct',\n",
       " 'numbing',\n",
       " 'GEAR',\n",
       " 'hammered',\n",
       " 'camoflague',\n",
       " 'thankfully',\n",
       " 'banner',\n",
       " 'required',\n",
       " 'catchup',\n",
       " 'grate',\n",
       " 'LOSE',\n",
       " 'impliment',\n",
       " 'outrage',\n",
       " 'sceptical',\n",
       " 'downwards',\n",
       " 'DAMAGE',\n",
       " 'ROOM',\n",
       " 'particles',\n",
       " 'laughing',\n",
       " 'Rng',\n",
       " 'articles',\n",
       " 'Plant',\n",
       " 'awesomeness',\n",
       " 'Ex',\n",
       " 'Ambassador',\n",
       " 'weapon',\n",
       " 'trove',\n",
       " 'Why',\n",
       " 'Trading',\n",
       " 'doubting',\n",
       " 'playable',\n",
       " 'corvette',\n",
       " 'axe',\n",
       " 'moneyI',\n",
       " 'Recently',\n",
       " 'Storage',\n",
       " 'becasue',\n",
       " 'STRATEGY',\n",
       " 'BOT',\n",
       " 'presented',\n",
       " 'diffrent',\n",
       " 'rushing',\n",
       " 'atrocious',\n",
       " 'Superb',\n",
       " 'Between',\n",
       " 'Mounts',\n",
       " 'proposition',\n",
       " 'strategies',\n",
       " 'Lina',\n",
       " 'culture',\n",
       " 'ReviewSimple',\n",
       " 'manipulate',\n",
       " 'smurf',\n",
       " 'GMs',\n",
       " 'greediness',\n",
       " 'trojan',\n",
       " 'hovercrafts',\n",
       " 'Highly',\n",
       " 'recognizable',\n",
       " 'nonsensical',\n",
       " 'stressed',\n",
       " 'prefers',\n",
       " 'flags',\n",
       " 'Tech',\n",
       " 'spooped',\n",
       " 'count',\n",
       " 'previous',\n",
       " 'setback',\n",
       " 'teammates',\n",
       " 'res',\n",
       " 'yo',\n",
       " 'soundtracks',\n",
       " 'ReviewHiRez',\n",
       " 'timeconsuming',\n",
       " 'presence',\n",
       " 'ReviewMost',\n",
       " 'reps',\n",
       " 'Down',\n",
       " 'Squad',\n",
       " 'abundant',\n",
       " 'beloved',\n",
       " 'HELP',\n",
       " 'Inventory',\n",
       " 'Collect',\n",
       " 'set',\n",
       " 'Cottontail',\n",
       " 'promotional',\n",
       " 'ensure',\n",
       " 'investing',\n",
       " 'gamesThe',\n",
       " 'tool',\n",
       " 'tolerate',\n",
       " 'Protectors',\n",
       " 'coding',\n",
       " 'offended',\n",
       " 'lookout',\n",
       " 'upsidedown',\n",
       " 'specimen',\n",
       " 'RO',\n",
       " 'lift',\n",
       " 'Read',\n",
       " 'Untill',\n",
       " 'offThe',\n",
       " 'knew',\n",
       " 'pixely',\n",
       " 'confort',\n",
       " 'eye',\n",
       " 'unrelated',\n",
       " 'Reviewwhen',\n",
       " 'Party',\n",
       " 'highschool',\n",
       " 'badIf',\n",
       " 'Gi',\n",
       " 'investment',\n",
       " 'refunded',\n",
       " 'flask',\n",
       " 'LIE',\n",
       " 'determined',\n",
       " 'delivering',\n",
       " 'dialogues',\n",
       " 'walking',\n",
       " 'vibe',\n",
       " 'Chazz',\n",
       " 'weaknesses',\n",
       " 'induced',\n",
       " 'OMG',\n",
       " 'fuing',\n",
       " 'advertising',\n",
       " 'store',\n",
       " 'DEFINITELY',\n",
       " 'actual',\n",
       " 'reminders',\n",
       " 'feels',\n",
       " 'leaves',\n",
       " 'file',\n",
       " 'JESUS',\n",
       " 'stagnation',\n",
       " 'gos',\n",
       " 'Tag',\n",
       " 'ordered',\n",
       " 'Hitler',\n",
       " 'neccessarily',\n",
       " 'insult',\n",
       " 'implement',\n",
       " 'outpost',\n",
       " 'declining',\n",
       " 'repeats',\n",
       " 'SAVE',\n",
       " 'Megas',\n",
       " 'HEAVILY',\n",
       " 'mash',\n",
       " 'comment',\n",
       " 'Halloween',\n",
       " 'universes',\n",
       " 'coaching',\n",
       " 'beatemup',\n",
       " 'yata',\n",
       " 'reason',\n",
       " 'Dieses',\n",
       " 'lagg',\n",
       " 'avoiding',\n",
       " 'address',\n",
       " 'eastern',\n",
       " 'weakest',\n",
       " 'Multiple',\n",
       " 'jews',\n",
       " 'cyborg',\n",
       " 'reroll',\n",
       " 'white',\n",
       " 'jungles',\n",
       " 'onto',\n",
       " 'Artwork',\n",
       " 'vent',\n",
       " 'verbal',\n",
       " 'Infestation',\n",
       " 'trample',\n",
       " 'cames',\n",
       " 'Fullscreen',\n",
       " 'sluggish',\n",
       " 'divided',\n",
       " 'topnotch',\n",
       " 'VoIP',\n",
       " 'worthwile',\n",
       " 'tenth',\n",
       " 'sails',\n",
       " 'alpha',\n",
       " 'Defeat',\n",
       " 'gated',\n",
       " 'CARS',\n",
       " 'fear',\n",
       " 'Hydrogen',\n",
       " 'uma',\n",
       " 'afterall',\n",
       " 'SICK',\n",
       " 'nope',\n",
       " 'corpses',\n",
       " 'equivalent',\n",
       " 'Foundry',\n",
       " 'documents',\n",
       " 'crushing',\n",
       " 'distorter',\n",
       " 'many',\n",
       " 'successfully',\n",
       " 'working',\n",
       " 'ridiculous',\n",
       " 'segments',\n",
       " 'intel',\n",
       " 'fast',\n",
       " 'SAYS',\n",
       " 'bloody',\n",
       " 'invading',\n",
       " 'toon',\n",
       " 'senseless',\n",
       " 'obliterated',\n",
       " 'offspring',\n",
       " 'dry',\n",
       " 'controller',\n",
       " 'fortifications',\n",
       " 'displaying',\n",
       " 'defenitly',\n",
       " 'mob',\n",
       " 'hackershackers',\n",
       " 'ridculous',\n",
       " 'lord',\n",
       " 'Rarely',\n",
       " 'league',\n",
       " 'Nuff',\n",
       " 'Behind',\n",
       " 'suspension',\n",
       " 'clunky',\n",
       " 'tut',\n",
       " 'lasers',\n",
       " 'infrastructure',\n",
       " 'stuttering',\n",
       " 'demonstrates',\n",
       " 'aboard',\n",
       " 'thisIf',\n",
       " 'spurts',\n",
       " 'GETTING',\n",
       " 'styleThe',\n",
       " 'funbut',\n",
       " 'luckily',\n",
       " 'guranteed',\n",
       " 'Korean',\n",
       " 'radaway',\n",
       " 'soviets',\n",
       " 'MagicThe',\n",
       " 'distract',\n",
       " 'tycoon',\n",
       " 'Name',\n",
       " 'mainstream',\n",
       " 'FULLY',\n",
       " 'manabase',\n",
       " 'blame',\n",
       " 'unistall',\n",
       " 'Duck',\n",
       " 'clicked',\n",
       " 'thinks',\n",
       " 'tips',\n",
       " 'cheaply',\n",
       " 'toll',\n",
       " 'privilege',\n",
       " 'scents',\n",
       " 'functionality',\n",
       " 'gameÂ',\n",
       " 'carpet',\n",
       " 'Path',\n",
       " 'burning',\n",
       " 'SHORT',\n",
       " 'Chest',\n",
       " 'calibrated',\n",
       " 'doenst',\n",
       " 'Shards',\n",
       " 'AINT',\n",
       " 'spenders',\n",
       " 'competative',\n",
       " 'metaphor',\n",
       " 'trolling',\n",
       " 'empathy',\n",
       " 'overwatch',\n",
       " 'erased',\n",
       " 'reduction',\n",
       " 'Sunderer',\n",
       " 'raven',\n",
       " 'ReviewBlack',\n",
       " 'doubles',\n",
       " 'demographic',\n",
       " 'swoop',\n",
       " 'die',\n",
       " 'QUIT',\n",
       " 'Puzzles',\n",
       " 'gameAfter',\n",
       " 'Desktop',\n",
       " 'wo',\n",
       " 'DP',\n",
       " 'Popular',\n",
       " 'pay',\n",
       " 'streamed',\n",
       " 'selfexplanatory',\n",
       " 'packs',\n",
       " 'favorable',\n",
       " 'racism',\n",
       " 'ally',\n",
       " 'availible',\n",
       " 'CW',\n",
       " 'Expansions',\n",
       " 'guarantees',\n",
       " 'fully',\n",
       " 'LAME',\n",
       " 'fate',\n",
       " 'Creating',\n",
       " 'deepen',\n",
       " 'vanilla',\n",
       " 'greatI',\n",
       " 'wrists',\n",
       " 'realistic',\n",
       " 'Mad',\n",
       " 'bottom',\n",
       " 'foreseeable',\n",
       " 'Complete',\n",
       " 'garbage',\n",
       " 'outweighs',\n",
       " 'huey',\n",
       " 'ReviewTutorial',\n",
       " 'CLONE',\n",
       " 'gambling',\n",
       " 'Canhard',\n",
       " 'holes',\n",
       " 'extremly',\n",
       " 'mutant',\n",
       " 'cheerful',\n",
       " 'unban',\n",
       " 'cartoonlike',\n",
       " 'brackets',\n",
       " 'PLZ',\n",
       " 'sustain',\n",
       " 'freebie',\n",
       " 'vez',\n",
       " 'youIve',\n",
       " 'voted',\n",
       " 'disrespectful',\n",
       " 'Tired',\n",
       " 'infantry',\n",
       " 'achievements',\n",
       " 'exchanges',\n",
       " 'dramatically',\n",
       " 'couldnt',\n",
       " 'connects',\n",
       " 'hoursI',\n",
       " 'systemThe',\n",
       " 'ignore',\n",
       " 'Leagues',\n",
       " 'miles',\n",
       " 'beacon',\n",
       " 'succeeding',\n",
       " 'trip',\n",
       " 'royally',\n",
       " 'racking',\n",
       " 'breathe',\n",
       " 'slurs',\n",
       " 'iracing',\n",
       " 'spreading',\n",
       " 'density',\n",
       " 'COMING',\n",
       " 'Scott',\n",
       " 'believable',\n",
       " 'ANIMALS',\n",
       " 'detailed',\n",
       " 'pheasants',\n",
       " 'irritating',\n",
       " 'diamond',\n",
       " 'Confused',\n",
       " 'independent',\n",
       " 'PERSON',\n",
       " 'Das',\n",
       " 'cluster',\n",
       " 'Sht',\n",
       " 'retardation',\n",
       " 'English',\n",
       " 'redstone',\n",
       " 'disposal',\n",
       " 'naval',\n",
       " 'faild',\n",
       " 'floor',\n",
       " 'forges',\n",
       " 'Overwatch',\n",
       " 'EAC',\n",
       " 'closest',\n",
       " 'robbed',\n",
       " 'sickening',\n",
       " 'Dragons',\n",
       " 'borrows',\n",
       " 'rejoice',\n",
       " 'mousekeyboard',\n",
       " 'dragging',\n",
       " 'Frequent',\n",
       " 'remake',\n",
       " 'multicolor',\n",
       " 'shameless',\n",
       " 'garages',\n",
       " 'ReviewInstalled',\n",
       " 'gametypes',\n",
       " 'mounted',\n",
       " 'sa',\n",
       " 'gravel',\n",
       " 'neverwinter',\n",
       " 'actionRPG',\n",
       " 'resourses',\n",
       " 'Hammerpoint',\n",
       " 'alters',\n",
       " 'feelings',\n",
       " 'gernades',\n",
       " 'composition',\n",
       " 'steep',\n",
       " 'youdo',\n",
       " 'ReviewOn',\n",
       " 'descriptions',\n",
       " 'Kraken',\n",
       " 'professional',\n",
       " 'sport',\n",
       " 'OS',\n",
       " 'afar',\n",
       " 'promo',\n",
       " 'Kings',\n",
       " 'planning',\n",
       " 'Ready',\n",
       " 'Colorado',\n",
       " 'donkey',\n",
       " 'piercing',\n",
       " 'unplug',\n",
       " 'itthis',\n",
       " 'distributing',\n",
       " 'similarly',\n",
       " 'mythology',\n",
       " 'cheeky',\n",
       " 'stomps',\n",
       " 'Today',\n",
       " 'ez',\n",
       " 'press',\n",
       " 'incrementally',\n",
       " 'arranging',\n",
       " 'unballanced',\n",
       " 'massacre',\n",
       " 'fire',\n",
       " 'zones',\n",
       " 'automation',\n",
       " 'Kukulkan',\n",
       " 'parts',\n",
       " 'corsa',\n",
       " 'painfull',\n",
       " 'suited',\n",
       " 'courage',\n",
       " 'Actual',\n",
       " 'increasingly',\n",
       " 'permadeath',\n",
       " 'gamesim',\n",
       " 'RNGbased',\n",
       " 'check',\n",
       " 'scammers',\n",
       " 'adjustment',\n",
       " 'accountI',\n",
       " 'Group',\n",
       " 'legitimate',\n",
       " 'Infinite',\n",
       " 'craps',\n",
       " 'Web',\n",
       " 'flamethrower',\n",
       " 'cranked',\n",
       " 'sneaking',\n",
       " 'glee',\n",
       " 'hemorrhaging',\n",
       " 'command',\n",
       " 'cliffs',\n",
       " 'building',\n",
       " 'Mostly',\n",
       " 'bullets',\n",
       " 'MODS',\n",
       " 'Alliance',\n",
       " 'considered',\n",
       " 'regarded',\n",
       " 'reader',\n",
       " 'thisAlso',\n",
       " 'map',\n",
       " 'Cloud',\n",
       " 'distant',\n",
       " 'Nearly',\n",
       " 'sequel',\n",
       " 'achieved',\n",
       " 'landscape',\n",
       " 'enoughI',\n",
       " 'layouts',\n",
       " 'goodOverall',\n",
       " 'belong',\n",
       " 'midnight',\n",
       " 'horible',\n",
       " 'relaunching',\n",
       " 'Licenses',\n",
       " 'esspecially',\n",
       " 'Yep',\n",
       " 'proving',\n",
       " 'drop',\n",
       " 'ur',\n",
       " 'knockoff',\n",
       " 'AKA',\n",
       " 'successively',\n",
       " 'bastard',\n",
       " 'progress',\n",
       " 'favorate',\n",
       " 'nonSteam',\n",
       " 'fifth',\n",
       " 'Diamondback',\n",
       " 'sway',\n",
       " 'explosions',\n",
       " 'stylised',\n",
       " 'bow',\n",
       " 'hacking',\n",
       " 'catagory',\n",
       " 'SAID',\n",
       " 'hurting',\n",
       " 'Rfactor',\n",
       " 'Wasteland',\n",
       " 'ReviewSeems',\n",
       " 'logic',\n",
       " 'tap',\n",
       " 'picked',\n",
       " 'Pistols',\n",
       " 'Acess',\n",
       " 'nominate',\n",
       " 'shoot',\n",
       " 'calming',\n",
       " 'havoc',\n",
       " 'specialized',\n",
       " 'shout',\n",
       " 'outplayed',\n",
       " 'Perception',\n",
       " 'uses',\n",
       " 'tournament',\n",
       " 'mashup',\n",
       " 'shaping',\n",
       " 'ins',\n",
       " 'acquired',\n",
       " 'Glitch',\n",
       " 'aforementioned',\n",
       " 'Real',\n",
       " 'ITEMS',\n",
       " 'Case',\n",
       " 'grappling',\n",
       " 'barriers',\n",
       " 'worldwide',\n",
       " 'parents',\n",
       " 'smoothness',\n",
       " 'payment',\n",
       " 'CLICKER',\n",
       " 'guided',\n",
       " 'arethe',\n",
       " 'Wizards',\n",
       " 'Rush',\n",
       " 'dark',\n",
       " 'Sarov',\n",
       " 'Elderscrolls',\n",
       " 'betterOverall',\n",
       " 'absolutely',\n",
       " 'meYou',\n",
       " 'leaving',\n",
       " 'touched',\n",
       " 'ashamed',\n",
       " 'prediction',\n",
       " 'dinosaur',\n",
       " 'funNow',\n",
       " 'litte',\n",
       " 'Come',\n",
       " 'PoE',\n",
       " 'relaxing',\n",
       " 'intervention',\n",
       " 'KDR',\n",
       " 'MATCHMAKING',\n",
       " 'theyre',\n",
       " 'cup',\n",
       " 'Everybody',\n",
       " 'spook',\n",
       " 'restrict',\n",
       " 'jetpack',\n",
       " 'Silence',\n",
       " 'AMMO',\n",
       " 'stimpacks',\n",
       " 'liscences',\n",
       " 'ultra',\n",
       " 'dependant',\n",
       " 'actives',\n",
       " 'Wich',\n",
       " 'IDK',\n",
       " 'demos',\n",
       " 'request',\n",
       " 'Turbine',\n",
       " 'foundry',\n",
       " 'stereotypes',\n",
       " 'assassin',\n",
       " 'argument',\n",
       " 'quad',\n",
       " 'realy',\n",
       " 'againIts',\n",
       " 'attachment',\n",
       " 'knifes',\n",
       " 'Controller',\n",
       " 'Adorable',\n",
       " ...}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(tokens)\n",
    "vocab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trenowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_clean_doc(doc, vocab):\n",
    " # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    " # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    " # filter out tokens not in vocab\n",
    "    tokens = [w for w in tokens if w in vocab]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens\n",
    "\n",
    "# load all docs in a directory\n",
    "def process_docs(directory, vocab, isTrain):\n",
    "   documents = list()\n",
    " # walk through all files in the folder\n",
    "   for filename in listdir(directory):\n",
    " # create the full path of the file to open\n",
    "      path = directory + '/' + filename\n",
    " # load the doc\n",
    "      doc = load_doc(path)\n",
    " # clean doc\n",
    "      tokens = train_clean_doc(doc, vocab)\n",
    " # add to list\n",
    "      documents.append(tokens)\n",
    "   return documents\n",
    " \n",
    "# load all training reviews\n",
    "positive_docs = process_docs(r'C:\\Users\\sjkli\\Desktop\\Rafinacja\\positive', vocab, True)\n",
    "negative_docs = process_docs(r'C:\\Users\\sjkli\\Desktop\\Rafinacja\\negative', vocab, True)\n",
    "train_docs = negative_docs + positive_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stwórz tokenizację\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(train_docs)\n",
    "\n",
    "# encodig 'dokumentów' do modelu sekwencyjnego\n",
    "encoded_docs = tokenizer.texts_to_sequences(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding pustymi _tokenami_\n",
    "max_length = max([len(s.split()) for s in train_docs])\n",
    "Xtrain = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#przypisywanie snetymentu do określonych wierszy (train_docs = neg + pos)\n",
    "ytrain = np.array([0 for _ in range(6775)] + [1 for _ in range(8872)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uwaga!!!!\n",
    "\n",
    "## parametry range() w ytest zalezą od tego ile plików wydzielono ręcznie z oryginalnie przetworzonych plików __positive__ i __negative__ do plików __\"test_negative\" i __\"test_positive\"__ w tym przypadku ręcznie wydzielono 752 negatywne i 1095 pozytyznych recenzji do z danych _treningowych_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_docs = process_docs(r'C:\\Users\\sjkli\\Desktop\\Rafinacja\\test_positive', vocab, False)\n",
    "negative_docs = process_docs(r'C:\\Users\\sjkli\\Desktop\\Rafinacja\\test_negative', vocab, False)\n",
    "test_docs = negative_docs + positive_docs\n",
    "# text na liczby\n",
    "encoded_docs = tokenizer.texts_to_sequences(test_docs)\n",
    "# wyrównywanie do największej długości jednej recenzji\n",
    "Xtest = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "# etykiety częsci testowej 750 negatywnych i 1095 pozytywnych\n",
    "ytest = np.array([0 for _ in range(752)] + [1 for _ in range(1095)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14907"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wielkość (largest integer value)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sam model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1600, 100)         1490700   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1593, 32)          25632     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 796, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25472)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                254730    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,771,073\n",
      "Trainable params: 1,771,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trenowanie (parametry typu epoki optimizer wybrane są na podstawie podręcznika)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "489/489 - 32s - loss: 0.5321 - accuracy: 0.7552 - 32s/epoch - 66ms/step\n",
      "Epoch 2/10\n",
      "489/489 - 32s - loss: 0.3488 - accuracy: 0.8905 - 32s/epoch - 66ms/step\n",
      "Epoch 3/10\n",
      "489/489 - 32s - loss: 0.2434 - accuracy: 0.9335 - 32s/epoch - 65ms/step\n",
      "Epoch 4/10\n",
      "489/489 - 31s - loss: 0.1775 - accuracy: 0.9570 - 31s/epoch - 64ms/step\n",
      "Epoch 5/10\n",
      "489/489 - 31s - loss: 0.1431 - accuracy: 0.9672 - 31s/epoch - 63ms/step\n",
      "Epoch 6/10\n",
      "489/489 - 31s - loss: 0.1196 - accuracy: 0.9728 - 31s/epoch - 63ms/step\n",
      "Epoch 7/10\n",
      "489/489 - 31s - loss: 0.1088 - accuracy: 0.9744 - 31s/epoch - 63ms/step\n",
      "Epoch 8/10\n",
      "489/489 - 31s - loss: 0.1012 - accuracy: 0.9757 - 31s/epoch - 64ms/step\n",
      "Epoch 9/10\n",
      "489/489 - 31s - loss: 0.0981 - accuracy: 0.9755 - 31s/epoch - 63ms/step\n",
      "Epoch 10/10\n",
      "489/489 - 30s - loss: 0.1073 - accuracy: 0.9709 - 30s/epoch - 61ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e79a448340>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xtrain, ytrain, epochs=10, verbose=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ewaluacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.957771\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(Xtest, ytest, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
